{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "from skimage import io\n",
    "import seaborn as sns\n",
    "import geopandas as gpd\n",
    "import contextily as cx\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive',force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip /content/drive/MyDrive/Post-hurricane.zip -d hurricane_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set main directory\n",
    "DIR = '/content/hurricane_data'\n",
    "\n",
    "#list folders\n",
    "os.listdir(DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of images per class in training set\n",
    "print('-------TRAIN-------')\n",
    "print(f\"No Damage: {len(os.listdir(os.path.join(DIR, 'train_another', 'no_damage')))}\")\n",
    "print(f\"Damage: {len(os.listdir(os.path.join(DIR, 'train_another', 'damage')))}\")\n",
    "\n",
    "# number of images per class in validation set\n",
    "print('-----VALIDATION-----')\n",
    "print(f\"No Damage: {len(os.listdir(os.path.join(DIR, 'validation_another', 'no_damage')))}\")\n",
    "print(f\"Damage: {len(os.listdir(os.path.join(DIR, 'validation_another', 'damage')))}\")\n",
    "\n",
    "# number of images per class in test set\n",
    "print('--------TEST--------')\n",
    "print(f\"No Damage: {len(os.listdir(os.path.join(DIR, 'test', 'no_damage')))}\")\n",
    "print(f\"Damage: {len(os.listdir(os.path.join(DIR, 'test', 'damage')))}\")\n",
    "\n",
    "# number of images per class in test set\n",
    "print('-------TEST 2-------')\n",
    "print(f\"No Damage: {len(os.listdir(os.path.join(DIR, 'test_another', 'no_damage')))}\")\n",
    "print(f\"Damage: {len(os.listdir(os.path.join(DIR, 'test_another', 'damage')))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load a sample image\n",
    "tile_path = os.path.join(DIR, 'train_another', 'no_damage' , '-96.987747_28.489092.jpeg')\n",
    "tile = io.imread(tile_path)\n",
    "\n",
    "#plot image\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.imshow(tile);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tile.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = (128, 128)\n",
    "batch_size = 32\n",
    "\n",
    "train_dir = os.path.join(DIR, 'train_another')\n",
    "val_dir = os.path.join(DIR, 'validation_another')\n",
    "\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    seed=42,\n",
    "    image_size=image_size,\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    val_dir,\n",
    "    seed=42,\n",
    "    image_size=image_size,\n",
    "    batch_size=batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_skipped = 0\n",
    "for folder_name in (\"damage\", \"no_damage\"):\n",
    "    folder_path = os.path.join(DIR,'train_another', folder_name)\n",
    "    for fname in os.listdir(folder_path):\n",
    "        fpath = os.path.join(folder_path, fname)\n",
    "        try:\n",
    "            fobj = open(fpath, \"rb\")\n",
    "            is_jfif = tf.compat.as_bytes(\"JFIF\") in fobj.peek(10)\n",
    "        finally:\n",
    "            fobj.close()\n",
    "\n",
    "        if not is_jfif:\n",
    "            num_skipped += 1\n",
    "\n",
    "            print(fpath)\n",
    "            # Delete corrupted image\n",
    "            #os.remove(fpath)\n",
    "\n",
    "print(f\"There are {num_skipped} corrupted images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training set folder\n",
    "train_dir = os.path.join(DIR, 'train_another')\n",
    "\n",
    "# get the list of jpegs from sub image class folders\n",
    "damage_imgs = [fn for fn in os.listdir(f'{train_dir}/damage') if fn.endswith('.jpeg')]\n",
    "no_damage_imgs = [fn for fn in os.listdir(f'{train_dir}/no_damage') if fn.endswith('.jpeg')]\n",
    "\n",
    "# randomly select 3 of each\n",
    "select_damage = np.random.choice(damage_imgs, 6, replace = False)\n",
    "select_no_damage = np.random.choice(no_damage_imgs, 6, replace = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting 2 x 3 image matrix\n",
    "fig = plt.figure(figsize = (8,6))\n",
    "for i in range(6):\n",
    "    if i < 3:\n",
    "        fp = f'{train_dir}/damage/{select_damage[i]}'\n",
    "        label = 'DAMAGE'\n",
    "    else:\n",
    "        fp = f'{train_dir}/no_damage/{select_no_damage[i-3]}'\n",
    "        label = 'NO DAMAGE'\n",
    "    ax = fig.add_subplot(2, 3, i+1)\n",
    "\n",
    "    fn = image.load_img(fp, target_size = (128,128), color_mode='rgb')\n",
    "    plt.imshow(fn)\n",
    "    plt.title(label)\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making n X m matrix\n",
    "def img2np(path, list_of_filename, size = (128, 128)):\n",
    "    # iterating through each file\n",
    "    for fn in list_of_filename:\n",
    "        fp = path + fn\n",
    "        current_image = image.load_img(fp, target_size = size, \n",
    "                                       color_mode = 'rgb')\n",
    "        # covert image to a matrix\n",
    "        img_ts = image.img_to_array(current_image)\n",
    "        # turn that into a vector / 1D array\n",
    "        img_ts = [img_ts.ravel()]\n",
    "        try:\n",
    "            # concatenate different images\n",
    "            full_mat = np.concatenate((full_mat, img_ts))\n",
    "        except UnboundLocalError: \n",
    "            # if not assigned yet, assign one\n",
    "            full_mat = img_ts\n",
    "    \n",
    "    return full_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training set folder\n",
    "val_dir = os.path.join(DIR, 'validation_another')\n",
    "val_damage_imgs = [fn for fn in os.listdir(f'{val_dir}/damage') if fn.endswith('.jpeg')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_array = img2np(f'{val_dir}/damage/', val_damage_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_array[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run it on our folders\n",
    "damage_arrays = img2np(f'{train_dir}/damage/', damage_imgs)\n",
    "no_damage_arrays = img2np(f'{train_dir}/no_damage/', no_damage_imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average Image by Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_mean_img(full_mat, title, size = (128, 128)):\n",
    "    # calculate the average\n",
    "    mean_img = np.mean(full_mat, axis = 0)\n",
    "    # reshape it back to a matrix\n",
    "    mean_img = mean_img.reshape(size)\n",
    "    plt.imshow(mean_img, vmin=85, vmax=110, cmap='plasma')\n",
    "    plt.title(f'Average {title}')\n",
    "    plt.axis('off')\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "    return mean_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "damage_mean = find_mean_img(damage_arrays, 'DAMAGE')\n",
    "no_damage_mean = find_mean_img(no_damage_arrays, 'NO DAMAGE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_std_img(full_mat, title, size = (128, 128)):\n",
    "    # calculate the average\n",
    "    var_img = np.std(full_mat, axis = 0)\n",
    "    # reshape it back to a matrix\n",
    "    var_img = var_img.reshape(size)\n",
    "    plt.imshow(var_img, vmin=20, vmax=70, cmap='plasma')\n",
    "    plt.title(f'Standard Deviation {title}')\n",
    "    plt.colorbar()\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    return var_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "damage_std = find_std_img(damage_arrays, 'DAMAGE')\n",
    "no_damage_std = find_std_img(no_damage_arrays, 'NO DAMAGE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contrast between average images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contrast_mean = damage_mean - no_damage_mean\n",
    "plt.imshow(contrast_mean, vmin=-15, vmax=15, cmap='bwr')\n",
    "plt.title(f'Difference Between Damage & No Damage Average')\n",
    "plt.colorbar()\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Geographic distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#damage set\n",
    "damage_df = pd.DataFrame(damage_imgs, columns=['Filename'])\n",
    "damage_coors =  damage_df.Filename.str.split('_', expand=True)\n",
    "damage_df = pd.concat([damage_df, damage_coors], axis=1)\n",
    "damage_df = damage_df.rename(columns={0: 'lon', 1: 'lat'})\n",
    "damage_df.lat = damage_df.lat.str.rstrip('.jpeg')\n",
    "damage_df['damage'] = 1\n",
    "#damage_df['file_size']\n",
    "\n",
    "#no_damage set\n",
    "no_damage_df = pd.DataFrame(no_damage_imgs, columns=['Filename'])\n",
    "no_damage_coors = no_damage_df.Filename.str.split('_', expand=True)\n",
    "no_damage_df = pd.concat([no_damage_df, no_damage_coors], axis=1)\n",
    "no_damage_df = no_damage_df.rename(columns={0: 'lon', 1: 'lat'})\n",
    "no_damage_df.lat = no_damage_df.lat.str.rstrip('.jpeg')\n",
    "no_damage_df['damage'] = 0\n",
    "\n",
    "#concatenate\n",
    "all_df = pd.concat([damage_df, no_damage_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert to geodataframe and convert to Web Mercator\n",
    "all_gdf = gpd.GeoDataFrame(all_df, geometry=gpd.points_from_xy(all_df.lon, all_df.lat))\n",
    "all_gdf = all_gdf.set_crs(epsg=4326)\n",
    "all_gdf = all_gdf.to_crs(epsg=3857)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot by damage class w/ basemap\n",
    "ax = all_gdf.plot(column='damage',categorical=True, figsize=(10, 10), alpha=0.8, s=1.5, legend=True, cmap='cool')\n",
    "cx.add_basemap(ax)\n",
    "plt.title(f'Point locations of Training Images, Damaged or Not')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert lat/long columns from text to float\n",
    "all_gdf.lon = all_gdf.lon.astype('float')\n",
    "all_gdf.lat = all_gdf.lat.astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot distribution of longitude values\n",
    "fig, (ax1, ax2) = plt.subplots(1,2, figsize=(10,5))\n",
    "sns.histplot(all_gdf[all_gdf.damage==0].lon, ax=ax1)\n",
    "fig.suptitle('Distribution of Longtitudes')\n",
    "ax1.set_xlim([-97, -93.5])\n",
    "ax1.set_title('No Damage')\n",
    "\n",
    "sns.histplot(all_gdf[all_gdf.damage==1].lon, ax=ax2)\n",
    "ax2.set_xlim([-97, -93.5])\n",
    "ax2.set_title('Damage');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot by damage class w/ basemap - zoomed in on southwest grouping\n",
    "southern_gdf = all_gdf[all_gdf.lon < -96]\n",
    "axx = southern_gdf.plot(column='damage',categorical=True, figsize=(10, 10), alpha=0.8, s=1.5, legend=True, cmap='cool')\n",
    "axx.set_xlim([-10798210.908-60000, -10782077.708+60000])\n",
    "cx.add_basemap(axx)\n",
    "plt.title(f'Point locations of Training Images, Damaged or Not (Southwestern Grouping)')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_damage_file_size(row):\n",
    "    file_path = os.path.join(DIR, 'train_another', 'damage', row['Filename'])\n",
    "    file_size = os.stat(file_path).st_size\n",
    "    return file_size\n",
    "\n",
    "def get_no_damage_file_size(row):\n",
    "    file_path = os.path.join(DIR, 'train_another', 'no_damage', row['Filename'])\n",
    "    file_size = os.stat(file_path).st_size\n",
    "    return file_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "damage_df['file_size'] = damage_df.apply((lambda row: get_damage_file_size(row)), axis=1)\n",
    "no_damage_df['file_size'] = no_damage_df.apply((lambda row: get_no_damage_file_size(row)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df = pd.concat([damage_df, no_damage_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(damage_df['file_size'].mean())\n",
    "print(no_damage_df['file_size'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=all_df, x='damage', y='file_size')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
